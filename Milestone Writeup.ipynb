{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb770e3b",
   "metadata": {},
   "source": [
    "# Milestone Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Acquisition and Description\n",
    "We got our data from Oikolab. They get their data from various sources, such as NOAA, GEFS, CHIRPS, and ERA5. The data came in a csv file, with a variety of variables to choose from, all of which we explored in our autoregression file, in which we decided which variables to focus on in our correlation matrix. \n",
    "Milestones:\n",
    "Linear regression models\n",
    "\tPreviously done\n",
    "        -Preprocessing data\n",
    "        -Encoded categorical data\n",
    "        -OLS Summary for each city\n",
    "        -Mean snowfall for February by year by city graphs\n",
    "\tNeed to do\n",
    "        -Add a regression line to plots\n",
    "        -Change x-axis ticks\n",
    "        -Add comments to this code\n",
    "Auto regression models\n",
    "\tPreviously done\n",
    "        -Preprocessing data\n",
    "        -Encoded categorical data\n",
    "        -Fit an auto-regression model with the SLC all Param data\n",
    "        -Get a predicted snowfall for Feb 10 2034 (which day is arbitrary)\n",
    "\tNeed to do\n",
    "        -Get an accuracy for regression model/other statistical analysis of the autoregression\n",
    "        -Find another model to make a comparison\n",
    "        -Add bullet for prediction for feb 2034 to other plots \n",
    "        -Possibly run other city datasets through the auto regression model.\n",
    "        -Clean code\n",
    "\n",
    "\n",
    "\t\n",
    "Data\n",
    "    Previously done\n",
    "        -Reformat data/other preprocessing. \n",
    "        -Create a correlation matrix to identify which variable correlates most with Snowfall in SLC\n",
    "        -Find historic mean, upper limit, lower limit  for Feb 1994-2024 in SLC\n",
    "    Need to do\n",
    "        -Show statistical significance or insignificance of data and plots.\n",
    "        -Make sure all datasets cover the same years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd418e",
   "metadata": {},
   "source": [
    "#Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31953874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ogden = \"Ogden_Data.csv\"\n",
    "provo = \"Provo_Data.csv\"\n",
    "slc = \"SLC_All_Param.csv\"\n",
    "ogden_df = pd.read_csv(ogden)\n",
    "provo_df = pd.read_csv(provo)\n",
    "slc_df = pd.read_csv(slc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f553e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogden_df['datetime (UTC)'] = pd.to_datetime(ogden_df['datetime (UTC)'])\n",
    "ogden_df[['latitude', 'longitude']] = ogden_df['coordinates (lat,lon)'].str.extract(r'\\(([^,]+), ([^)]+)\\)').astype(float)\n",
    "\n",
    "provo_df['datetime (UTC)'] = pd.to_datetime(provo_df['datetime (UTC)'])\n",
    "provo_df[['latitude', 'longitude']] = provo_df['coordinates (lat,lon)'].str.extract(r'\\(([^,]+), ([^)]+)\\)').astype(float)\n",
    "\n",
    "slc_df['datetime (UTC)'] = pd.to_datetime(slc_df['datetime (UTC)'])\n",
    "slc_df[['latitude', 'longitude']] = slc_df['coordinates (lat,lon)'].str.extract(r'\\(([^,]+), ([^)]+)\\)').astype(float)\n",
    "\n",
    "ogden_df_encoded = pd.get_dummies(ogden_df, columns=['model (name)'])\n",
    "provo_df_encoded = pd.get_dummies(provo_df, columns=['model (name)'])\n",
    "slc_df_encoded = pd.get_dummies(slc_df, columns=['model (name)'])\n",
    "\n",
    "ogden_df_encoded['hour'] = ogden_df_encoded['datetime (UTC)'].dt.hour\n",
    "ogden_df_encoded['day'] = ogden_df_encoded['datetime (UTC)'].dt.day\n",
    "ogden_df_encoded['month'] = ogden_df_encoded['datetime (UTC)'].dt.month\n",
    "ogden_df_encoded['year'] = ogden_df_encoded['datetime (UTC)'].dt.year\n",
    "\n",
    "provo_df_encoded['hour'] = provo_df_encoded['datetime (UTC)'].dt.hour\n",
    "provo_df_encoded['day'] = provo_df_encoded['datetime (UTC)'].dt.day\n",
    "provo_df_encoded['month'] = provo_df_encoded['datetime (UTC)'].dt.month\n",
    "provo_df_encoded['year'] = provo_df_encoded['datetime (UTC)'].dt.year\n",
    "\n",
    "slc_df_encoded['hour'] = slc_df_encoded['datetime (UTC)'].dt.hour\n",
    "slc_df_encoded['day'] = slc_df_encoded['datetime (UTC)'].dt.day\n",
    "slc_df_encoded['month'] = slc_df_encoded['datetime (UTC)'].dt.month\n",
    "slc_df_encoded['year'] = slc_df_encoded['datetime (UTC)'].dt.year\n",
    "\n",
    "ogden_df_encoded.drop(['datetime (UTC)', 'coordinates (lat,lon)'], axis=1, inplace=True)\n",
    "provo_df_encoded.drop(['datetime (UTC)', 'coordinates (lat,lon)'], axis=1, inplace=True)\n",
    "slc_df_encoded.drop(['datetime (UTC)', 'coordinates (lat,lon)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['temperature (degC)', 'relative_humidity (0-1)', 'total_precipitation (mm of water equivalent)', 'total_cloud_cover (0-1)']\n",
    "target_variable = 'snowfall (mm of water equivalent)'\n",
    "\n",
    "ogden_data = ogden_df_encoded[['month', 'year', target_variable] + features].copy()\n",
    "provo_data = provo_df_encoded[['month', 'year', target_variable] + features].copy()\n",
    "slc_data = slc_df_encoded[['month', 'hour', 'year', target_variable] + features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76438705",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogden_filtered_data = ogden_data[ogden_data['month'] == 2]\n",
    "provo_filtered_data = provo_data[provo_data['month'] == 2]\n",
    "slc_filtered_data = slc_data[(slc_data['hour'] == 10) & (slc_data['month'] == 2)]\n",
    "\n",
    "slc_yearly_mean = slc_filtered_data.groupby('year').mean()\n",
    "\n",
    "slc_yearly_mean = slc_yearly_mean.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "ogden_x = ogden_filtered_data['year']\n",
    "ogden_y = ogden_filtered_data['snowfall (mm of water equivalent)']\n",
    "ogden_result = sm.OLS(ogden_y, ogden_x).fit()\n",
    "\n",
    "provo_x = provo_filtered_data['year']\n",
    "provo_y = provo_filtered_data['snowfall (mm of water equivalent)']\n",
    "provo_result = sm.OLS(provo_y, provo_x).fit()\n",
    "\n",
    "slc_x = slc_yearly_mean['year']\n",
    "slc_y = slc_yearly_mean['snowfall (mm of water equivalent)']\n",
    "slc_result = sm.OLS(slc_y, slc_x).fit()\n",
    "\n",
    "print(\"Ogden OLS\")\n",
    "print(ogden_result.summary())\n",
    "print(\"Provo OLS\")\n",
    "print(provo_result.summary())\n",
    "print(\"Salt Lake City OLS\")\n",
    "print(slc_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ogden_x, ogden_y, marker='o')\n",
    "\n",
    "plt.title('Mean snowfall for February by Year in Ogden')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean snowfall (mm of water equivalent)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(provo_x, provo_y, marker='o')\n",
    "\n",
    "plt.title('Mean snowfall for February by Year in Provo')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean snowfall (mm of water equivalent)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(slc_x, slc_y, marker='o')\n",
    "\n",
    "plt.title('Mean snowfall for February by Year in Salt Lake City')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean snowfall (mm of water equivalent)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e57dbc",
   "metadata": {},
   "source": [
    "# Auto Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb43b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'SLC_all_param.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5172833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for all features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parse datetime and split coordinates\n",
    "df['datetime (UTC)'] = pd.to_datetime(df['datetime (UTC)'])\n",
    "df[['latitude', 'longitude']] = df['coordinates (lat,lon)'].str.extract(r'\\(([^,]+), ([^)]+)\\)').astype(float)\n",
    "\n",
    "# Drop columns with 50% or more null values\n",
    "df = df.dropna(thresh=len(df) * 0.7, axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=['model (name)'])\n",
    "\n",
    "# break down the UTC t from datetime\n",
    "df_encoded['hour'] = df_encoded['datetime (UTC)'].dt.hour\n",
    "df_encoded['day'] = df_encoded['datetime (UTC)'].dt.day\n",
    "df_encoded['month'] = df_encoded['datetime (UTC)'].dt.month\n",
    "\n",
    "# Drop the original datetime and coordinates columns\n",
    "df_encoded.drop(['datetime (UTC)', 'coordinates (lat,lon)'], axis=1, inplace=True)\n",
    "\n",
    "# Check if df_encoded is empty\n",
    "#  print(df_encoded.head())\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_encoded.select_dtypes(include=['float64', 'int64']))  # Scale only numerical features\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=df_encoded.select_dtypes(include=['float64', 'int64']).columns)\n",
    "df_encoded[df_scaled.columns] = df_scaled\n",
    "\n",
    "# Calculate correlation with target variable\n",
    "correlation_with_target = df_encoded.corr()['snowfall (mm of water equivalent)'].abs()\n",
    "\n",
    "# Select top 5 most influential features (excluding the target variable)\n",
    "top_5_features = correlation_with_target.sort_values(ascending=False).index[1:6]\n",
    "\n",
    "print(\"Top 5 features and their correlation with the target variable:\")\n",
    "for feature in top_5_features:\n",
    "    correlation_value = correlation_with_target[feature]\n",
    "    print(f\"{feature}: {correlation_value:.2f}\")\n",
    "\n",
    "# Create correlation matrix using only the top 5 features and the target variable\n",
    "correlation_matrix = df_encoded[top_5_features].join(df_encoded['snowfall (mm of water equivalent)']).corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"fontsize\":10, \"weight\": \"bold\"})\n",
    "plt.title(\"Correlation Matrix of Top 5 Most Influential Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_features = correlation_with_target.sort_values(ascending=False).index[1:11]\n",
    "\n",
    "# Print top 10 features and their correlation values\n",
    "print(\"Top 10 features and their correlation with the target variable:\")\n",
    "for feature in top_10_features:\n",
    "    correlation_value = correlation_with_target[feature]\n",
    "    print(f\"{feature}: {correlation_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Parse datetime and split coordinates\n",
    "df['datetime (UTC)'] = pd.to_datetime(df['datetime (UTC)'])\n",
    "\n",
    "# Select features and target variable\n",
    "features = ['temperature (degC)', 'relative_humidity (0-1)', 'total_precipitation (mm of water equivalent)', 'total_cloud_cover (0-1)']\n",
    "target_variable = 'snowfall (mm of water equivalent)'\n",
    "\n",
    "data = df[['datetime (UTC)', target_variable] + features].copy()\n",
    "\n",
    "data['hour'] = data['datetime (UTC)'].dt.hour\n",
    "data['day'] = data['datetime (UTC)'].dt.day\n",
    "data['month'] = data['datetime (UTC)'].dt.month\n",
    "data['year'] = data['datetime (UTC)'].dt.year\n",
    "\n",
    "data['date'] = pd.to_datetime(data[['year', 'month', 'day']])\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "# Drop the original datetime and coordinates columns\n",
    "data.drop(['datetime (UTC)'], axis=1, inplace=True)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d83134",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[(data['hour'] == 10) & (data['month'] == 2)]\n",
    "\n",
    "# Create a DataFrame from the filtered data\n",
    "df = pd.DataFrame(filtered_data.copy())\n",
    "df2 = df.copy()\n",
    "\n",
    "snowfall_mean = df['snowfall (mm of water equivalent)'].mean()\n",
    "\n",
    "print(\"Mean snowfall (mm of water equivalent) in febs (1994-2024):\", snowfall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e822e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming filtered_data contains the DataFrame you provided earlier\n",
    "\n",
    "# Define the features and target variable\n",
    "features = ['temperature (degC)', 'relative_humidity (0-1)', 'total_precipitation (mm of water equivalent)', 'total_cloud_cover (0-1)', 'date']\n",
    "target_variable = 'snowfall (mm of water equivalent)'\n",
    "\n",
    "# Recreate the index with a specific frequency (assuming daily frequency)\n",
    "df.index = pd.date_range(start=df.index.min(), periods=len(df), freq='D')\n",
    "\n",
    "# Fit autoregression model\n",
    "model = AutoReg(df[target_variable], lags=1)  # Assuming lag order is 1\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Make predictions\n",
    "predictions = model_fit.predict(start='2034-02-10', end='2034-02-10', dynamic=False)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d960d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date for which you want to make the prediction\n",
    "prediction_date = '2034-02-28'\n",
    "prediction_date = '2034-02-28'\n",
    "# Predict snowfall for the specified date\n",
    "prediction = model_fit.predict(start=prediction_date, end=prediction_date)\n",
    "\n",
    "print(\"Predicted snowfall on February 10, 2034:\", prediction.values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics from historical data\n",
    "historical_mean = df['snowfall (mm of water equivalent)'].mean()\n",
    "historical_std = df['snowfall (mm of water equivalent)'].std()\n",
    "\n",
    "# Compare with predicted snowfall\n",
    "predicted_snowfall = prediction.values[0]  # Your predicted snowfall value\n",
    "significance_level = 0.95  # For example, use 95% confidence interval\n",
    "\n",
    "# Calculate the upper and lower bounds of significance\n",
    "upper_bound = historical_mean + significance_level * historical_std\n",
    "lower_bound = historical_mean - significance_level * historical_std\n",
    "\n",
    "print(\"Historic Mean:\")\n",
    "print(historical_mean)\n",
    "\n",
    "print(\"Upper:\")\n",
    "print(upper_bound)\n",
    "print(\"Lower:\")\n",
    "print(lower_bound)\n",
    "print(\"Predicted:\")\n",
    "print(predicted_snowfall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ee938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for February (month = 2)\n",
    "february_data = df2[df2['month'] == 2]\n",
    "\n",
    "# Group by year, calculate the mean\n",
    "yearly_mean = february_data.groupby('year').mean()\n",
    "\n",
    "# Reset index to make 'year' as a column\n",
    "yearly_mean = yearly_mean.reset_index()\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(yearly_mean['year'], yearly_mean['snowfall (mm of water equivalent)'], marker='o')\n",
    "\n",
    "plt.title('Mean snowfall for February by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean snowfall (mm of water equivalent)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find historical maximum and minimum snowfall values\n",
    "historical_max = df2['snowfall (mm of water equivalent)'].max()\n",
    "historical_min = df2['snowfall (mm of water equivalent)'].min()\n",
    "\n",
    "# Find dates corresponding to the maximum and minimum snowfall values\n",
    "date_max = df2[df2['snowfall (mm of water equivalent)'] == historical_max].index[0]\n",
    "date_min = df2[df2['snowfall (mm of water equivalent)'] == historical_min].index[0]\n",
    "\n",
    "# Print the maximum and minimum values along with their corresponding dates\n",
    "print(\"Historical Maximum Snowfall:\", historical_max, \"mm\")\n",
    "print(\"Date of Maximum Snowfall:\", date_max)\n",
    "print(\"Historical Minimum Snowfall:\", historical_min, \"mm\")\n",
    "print(\"Date of Minimum Snowfall:\", date_min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
